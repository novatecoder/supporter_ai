import streamlit as st
import requests
import json
import numpy as np
import pyaudio
import threading
import asyncio
from supporter_ai.sensory.whisper_engine import WhisperEngine
from supporter_ai.expression.tts_engine import TTSEngine

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Supporter AI Debug Console", layout="wide")

# --- [ì—”ì§„ ë° ìƒíƒœ ì´ˆê¸°í™”] ---
@st.cache_resource
def get_engines():
    """ì—”ì§„ë“¤ì„ ìºì‹±í•˜ì—¬ ì¤‘ë³µ ë¡œë“œë¥¼ ë°©ì§€í•©ë‹ˆë‹¤."""
    return WhisperEngine(), TTSEngine()

stt_engine, tts_engine = get_engines()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "is_recording" not in st.session_state:
    st.session_state.is_recording = False
if "audio_buffer" not in st.session_state:
    st.session_state.audio_buffer = []
if "stop_event" not in st.session_state:
    st.session_state.stop_event = threading.Event()

# --- [ì˜¤ë””ì˜¤ ë° ì„œë²„ í†µì‹  ë¡œì§] ---

def audio_recording_worker(stop_event, buffer):
    """ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤ì œ ë§ˆì´í¬ ì†Œë¦¬ë¥¼ ìº¡ì²˜í•©ë‹ˆë‹¤."""
    CHUNK, FORMAT, CHANNELS, RATE = 1024, pyaudio.paInt16, 1, 16000
    p = pyaudio.PyAudio()
    try:
        stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, 
                        input=True, frames_per_buffer=CHUNK)
        buffer.clear()
        while not stop_event.is_set():
            data = stream.read(CHUNK, exception_on_overflow=False)
            buffer.append(np.frombuffer(data, dtype=np.int16))
        stream.stop_stream()
        stream.close()
    finally:
        p.terminate()

async def process_voice_input(user_id, session_id):
    """ë…¹ìŒëœ ë²„í¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ì„œë²„ì— ì „ì†¡í•©ë‹ˆë‹¤."""
    if not st.session_state.audio_buffer: return
    
    with st.spinner("ëª©ì†Œë¦¬ ë¶„ì„ ì¤‘..."):
        audio_data = np.concatenate(st.session_state.audio_buffer).astype(np.float32) / 32768.0
        text = await stt_engine.transcribe(audio_data)
        
    if text:
        send_to_server(user_id, session_id, text)

def send_to_server(user_id, session_id, message):
    """ì„œë²„ë¡œ JSON ë°ì´í„°ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤."""
    try:
        response = requests.post(
            "http://localhost:8080/api/v1/chat",
            json={"user_id": user_id, "session_id": session_id, "message": message}
        )
        if response.status_code == 200:
            data = response.json()
            st.session_state.chat_history.append({"role": "user", "content": message})
            st.session_state.chat_history.append({
                "role": "assistant", 
                "content": data["response"],
                "debug_info": data.get("metadata", {})
            })
    except Exception as e:
        st.error(f"ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {str(e)}")

# --- [UI êµ¬ì„±] ---
st.title("ğŸ¤– Supporter AI ë°ëª¨")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ğŸ‘¤ ì„¤ì •")
    user_id = st.text_input("User ID", value="kwh_01")
    session_id = st.text_input("Session ID", value="sess_01")
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.chat_history = []
        st.rerun()

# 1. ì±„íŒ… ë©”ì‹œì§€ ì¶œë ¥ ì˜ì—­ (ê³ ì • ë†’ì´ ë° ìë™ ìŠ¤í¬ë¡¤)
chat_container = st.container(height=600)

with chat_container:
    for i, chat in enumerate(st.session_state.chat_history):
        with st.chat_message(chat["role"]):
            st.markdown(chat["content"])
            
            # AI ë‹µë³€ì¸ ê²½ìš° TTS ì¬ìƒ ë²„íŠ¼ê³¼ ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€
            if chat["role"] == "assistant":
                col_tts, col_debug = st.columns([1, 4])
                with col_tts:
                    # ê° ë²„íŠ¼ì— ê³ ìœ í•œ key ë¶€ì—¬ (i ì‚¬ìš©)
                    if st.button("ğŸ”Š ì¬ìƒ", key=f"tts_{i}"):
                        asyncio.run(tts_engine.speak(chat["content"]))
                
                if "debug_info" in chat:
                    with st.expander("ğŸ› ï¸ ë””ë²„ê¹… ë°ì´í„°"):
                        st.json(chat["debug_info"])

# 2. í•˜ë‹¨ ì…ë ¥ ì˜ì—­
st.markdown("---")
input_col1, input_col2 = st.columns([1, 5])

with input_col1:
    if not st.session_state.is_recording:
        if st.button("ğŸ™ï¸ ë…¹ìŒ ì‹œì‘", use_container_width=True):
            st.session_state.is_recording = True
            st.session_state.stop_event.clear()
            st.session_state.audio_buffer = []
            threading.Thread(target=audio_recording_worker, args=(st.session_state.stop_event, st.session_state.audio_buffer)).start()
            st.rerun()
    else:
        if st.button("ğŸ›‘ ì „ì†¡", type="primary", use_container_width=True):
            st.session_state.stop_event.set()
            st.session_state.is_recording = False
            asyncio.run(process_voice_input(user_id, session_id))
            st.rerun()

with input_col2:
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”..."):
        send_to_server(user_id, session_id, prompt)
        st.rerun()

if st.session_state.is_recording:
    st.toast("ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤...", icon="ğŸ™ï¸")