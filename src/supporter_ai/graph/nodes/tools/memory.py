# src/supporter_ai/graph/nodes/tools/memory.py
import json
import logging
import redis.asyncio as redis
from supporter_ai.common.config import settings
from supporter_ai.graph.state import SupporterState
from langchain_core.messages import messages_from_dict, messages_to_dict, HumanMessage, AIMessage, SystemMessage
from supporter_ai.graph.nodes.brain.reasoning import get_llm

logger = logging.getLogger(__name__)
redis_client = redis.Redis(host=settings.REDIS_HOST, port=settings.REDIS_PORT, decode_responses=True)

async def load_memory_node(state: SupporterState):
    session_id = state.get("session_id", "default")
    raw_data = await redis_client.get(f"supporter:context:{session_id}")
    if raw_data:
        data = json.loads(raw_data)
        return {
            "messages": messages_from_dict(data.get("messages", [])),
            "summary": data.get("summary", ""),
            "blood_type": state.get("blood_type") or data.get("blood_type", "A")
        }
    return state

async def update_history_node(state: SupporterState):
    """í˜„ì¬ í„´ì˜ ëŒ€í™”ë¥¼ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì „ì²´ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±)"""
    messages = state.get("messages", [])
    new_user_msg = HumanMessage(content=state["input_text"])
    new_ai_msg = AIMessage(content=state.get("final_output", {}).get("text", ""))
    
    # ë¦¬ë“€ì„œê°€ ì—†ìœ¼ë¯€ë¡œ í•©ì³ì§„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì—¬ ìƒíƒœë¥¼ ê°±ì‹ í•¨
    return {"messages": messages + [new_user_msg, new_ai_msg]}

async def summarize_node(state: SupporterState):
    """ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ìš”ì•½ ìˆ˜í–‰ ë° ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ë¹„ìš°ê¸°"""
    messages = state.get("messages", [])
    
    # 10ê°œ ì´í•˜ì¼ ë•ŒëŠ” ì‹¤í–‰ ì•ˆ í•¨ (ì´ë•Œ ë””ë²„ê·¸ ë¡œê·¸ê°€ ì•ˆ ì°í ìˆ˜ ìˆìŒ)
    if len(messages) <= 10:
        return {}

    logger.info(f"ğŸš€ ë©”ì‹œì§€ {len(messages)}ê°œ ë„ë‹¬. ìš”ì•½ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    llm = get_llm(temperature=0.1)
    existing_summary = state.get("summary", "")
    
    summary_prompt = f"""ë„ˆëŠ” ê¸°ì–µ ê´€ë¦¬ìì•¼. í† í° ì œí•œì„ ìœ„í•´ ì •ë³´ë¥¼ ì••ì¶•í•´.
[ê¸°ì¡´ ìš”ì•½]: {existing_summary}
[ìµœì‹  ëŒ€í™”]: {messages[:-4]}
ì§€ì¹¨: ì´ë¦„ê³¼ í•µì‹¬ ì·¨í–¥ì€ ì ˆëŒ€ ë¹¼ì§€ ë§ê³  200ì ë‚´ì™¸ë¡œ ì—…ë°ì´íŠ¸í•´."""

    res = await llm.ainvoke([SystemMessage(content="ê¸°ì–µ ì••ì¶• ì—”ì§„"), HumanMessage(content=summary_prompt)])
    
    # ìš”ì•½ë³¸ì„ ê°±ì‹ í•˜ê³ , ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ëŠ” ìµœê·¼ 4ê°œë§Œ ë‚¨ê²¨ì„œ 'ë¹„ì›Œì¤Œ' (í† í° í™•ë³´)
    return {
        "summary": res.content.strip(),
        "messages": messages[-4:] 
    }

async def save_memory_node(state: SupporterState):
    session_id = state.get("session_id", "default")
    data = {
        "messages": messages_to_dict(state["messages"]), 
        "summary": state.get("summary", ""),
        "blood_type": state.get("blood_type")
    }
    await redis_client.setex(f"supporter:context:{session_id}", 3600, json.dumps(data))
    logger.info(f"ğŸ’¾ ì„¸ì…˜ {session_id} ì €ì¥ ì™„ë£Œ.")
    return state