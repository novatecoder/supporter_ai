import traceback
import uvicorn
from contextlib import asynccontextmanager
from typing import Dict, Any, List, Optional
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from loguru import logger

from supporter_ai.graph.workflow import create_supporter_workflow
from supporter_ai.common.config import settings

# ì•± ìƒíƒœ ê³µìœ 
app_state: Dict[str, Any] = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    try:
        logger.info("ğŸš€ Supporter AI í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ ë¡œë”© ì¤‘...")
        # ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ì»´íŒŒì¼
        app_state["graph"] = await create_supporter_workflow()
        yield 
    except Exception as e:
        logger.error(f"âŒ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {traceback.format_exc()}")
        raise e
    finally:
        app_state.clear()

app = FastAPI(title="Supporter AI API", lifespan=lifespan)

# í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ ê·œê²©
class ChatRequest(BaseModel):
    user_id: str = "kwh_01"
    session_id: str = "sess_01"
    message: str = "ì•ˆë…•"
    blood_type: Optional[str] = "A"               # ì„¸ì…˜ ì„¤ì •ê°’
    enabled_tools: Optional[List[str]] = []        # í™œì„±í™” ë„êµ¬ í”Œë˜ê·¸
    disabled_tools: Optional[List[str]] = []

@app.post("/api/v1/chat")
async def chat(req: ChatRequest):
    graph = app_state.get("graph")
    if not graph:
        raise HTTPException(status_code=503, detail="ì‹œìŠ¤í…œ ë¡œë”© ì¤‘")

    # ê·¸ë˜í”„ ì‹œì‘ ìƒíƒœ ì„¤ì • (state.py ê·œê²© ì¤€ìˆ˜)
    initial_state = {
        "input_text": req.message,
        "user_id": req.user_id,
        "session_id": req.session_id,
        "blood_type": req.blood_type,
        "enabled_tools": req.enabled_tools,
        "disabled_tools": req.disabled_tools,
        "messages": [] # load_memory_nodeì—ì„œ ì±„ì›Œì§ˆ ì˜ˆì •
    }

    try:
        # ë­ê·¸ë˜í”„ ì‹¤í–‰
        final_state = await graph.ainvoke(initial_state)
        
        # [ìˆ˜ì • í¬ì¸íŠ¸] expression_nodeì—ì„œ ìƒì„±ëœ 'final_output'ì„ ì¶”ì¶œ
        # response í•„ë“œê°€ ë¹„ì–´ìˆì§€ ì•Šë„ë¡ í™•ì‹¤í•˜ê²Œ ë§¤í•‘í•©ë‹ˆë‹¤.
        ai_response = final_state.get("final_output")
        
        # ë§Œì•½ ì–´ë–¤ ì´ìœ ë¡œë“  final_outputì´ ì—†ìœ¼ë©´ ë°©ì–´ì ìœ¼ë¡œ ìƒì„±
        if not ai_response or not isinstance(ai_response, dict):
            ai_response = {
                "text": "ë¯¸ì•ˆí•´, ëŒ€ë‹µì„ ì™„ì„±í•˜ì§€ ëª»í–ˆì–´. ë‹¤ì‹œ ë§í•´ì¤„ë˜?",
                "emotion": "sad",
                "action": "none"
            }

        # í´ë¼ì´ì–¸íŠ¸ ë””ë²„ê¹…ìš© ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            "blood_type": final_state.get("blood_type"),
            "mood": final_state.get("mood_state"),
            "thought": final_state.get("internal_thought"),
            "search_results": final_state.get("search_results"),
            "summary": final_state.get("summary"),
            "active_tools": final_state.get("enabled_tools")
        }

        # ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        return {
            "status": "success", 
            "response": ai_response,  # ì´ ë°ì´í„°ê°€ demo_appì˜ ë©”ì‹œì§€ë¡œ ì¶œë ¥ë¨
            "metadata": metadata
        }
        
    except Exception as e:
        logger.error(f"âŒ ì±„íŒ… ì‹¤í–‰ ì—ëŸ¬: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run("supporter_ai.main:app", host="0.0.0.0", port=settings.APP_PORT, reload=settings.DEBUG)