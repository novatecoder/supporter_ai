import traceback
import uvicorn
import time
from contextlib import asynccontextmanager
from typing import Dict, Any, List, Optional
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from loguru import logger

from supporter_ai.graph.workflow import create_supporter_workflow
from supporter_ai.common.config import settings

# ì•± ìƒíƒœ ê³µìœ 
app_state: Dict[str, Any] = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ ë­ê·¸ë˜í”„ ì—”ì§„ ë¡œë”©"""
    try:
        logger.info("ğŸš€ Supporter AI í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ ë¡œë”© ì¤‘...")
        # ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ì»´íŒŒì¼
        app_state["graph"] = await create_supporter_workflow()
        yield 
    except Exception as e:
        logger.error(f"âŒ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {traceback.format_exc()}")
        raise e
    finally:
        app_state.clear()

app = FastAPI(title="Supporter AI API", lifespan=lifespan)

# í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ ê·œê²©
class ChatRequest(BaseModel):
    user_id: str = "kwh_01"
    session_id: str = "sess_01"
    message: str = "ì•ˆë…•"
    blood_type: Optional[str] = "A"               # ì„¸ì…˜ ì„¤ì •ê°’
    enabled_tools: Optional[List[str]] = []        # í™œì„±í™” ë„êµ¬ í”Œë˜ê·¸
    disabled_tools: Optional[List[str]] = []

async def run_post_processing(graph, state: Dict[str, Any]):
    """
    ìš”ì•½(Summarize), ì €ì¥(Save), ì„±ì°°(Reflection) ë“± ë¬´ê±°ìš´ ì‘ì—…ì„ 
    ì‚¬ìš©ìì—ê²Œ ì‘ë‹µì„ ë³´ë‚¸ ë’¤ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    í˜„ì¬ workflow êµ¬ì¡°ìƒ ainvoke ë‚´ë¶€ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì§€ë§Œ, 
    ë¡œê·¸ë¥¼ í†µí•´ ì‹¤í–‰ ì—¬ë¶€ë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.
    """
    try:
        # ìš”ì•½ ë…¸ë“œê°€ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ ë¡œê·¸ í™•ì¸
        summary = state.get("summary", "")
        if summary:
            logger.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ìš”ì•½ ì™„ë£Œ: {summary[:30]}...")
    except Exception as e:
        logger.error(f"âŒ ì‚¬í›„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

@app.post("/api/v1/chat")
async def chat(req: ChatRequest, background_tasks: BackgroundTasks):
    graph = app_state.get("graph")
    if not graph:
        raise HTTPException(status_code=503, detail="ì‹œìŠ¤í…œ ë¡œë”© ì¤‘")

    # ê·¸ë˜í”„ ì‹œì‘ ìƒíƒœ ì„¤ì •
    initial_state = {
        "input_text": req.message,
        "user_id": req.user_id,
        "session_id": req.session_id,
        "blood_type": req.blood_type,
        "enabled_tools": req.enabled_tools,
        "disabled_tools": req.disabled_tools,
        "messages": [] # load_memory_nodeì—ì„œ Redis ë°ì´í„°ë¡œ ì±„ì›Œì§
    }

    try:
        # 1. ë­ê·¸ë˜í”„ ì‹¤í–‰
        # [ì°¸ê³ ] í˜„ì¬ workflow êµ¬ì¡°ìƒ save_memoryê¹Œì§€ ì¼ì§ì„ ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        # recursion_limitì„ 50ìœ¼ë¡œ ëŠ˜ë ¤ ë£¨í”„ ì—ëŸ¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
        final_state = await graph.ainvoke(
            initial_state, 
            config={"recursion_limit": 50}
        )
        
        # 2. ê²°ê³¼ ì¶”ì¶œ
        ai_response = final_state.get("final_output")
        
        # ë°©ì–´ì  ì½”ë“œ: ì‘ë‹µì´ ì—†ëŠ” ê²½ìš°
        if not ai_response or not isinstance(ai_response, dict):
            ai_response = {
                "text": "ë¯¸ì•ˆí•´, ëŒ€ë‹µì„ ì¤€ë¹„í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ìƒê²¼ì–´. ë‹¤ì‹œ ë§í•´ì¤„ë˜?",
                "emotion": "sad",
                "action": "none"
            }

        # 3. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡
        # ìš”ì•½ ë° ì„±ì°° ê²°ê³¼ê°€ í¬í•¨ëœ ìƒíƒœë¥¼ ë°±ê·¸ë¼ìš´ë“œ ë¡œê·¸ì— ë‚¨ê¹ë‹ˆë‹¤.
        background_tasks.add_task(run_post_processing, graph, final_state)

        # 4. í´ë¼ì´ì–¸íŠ¸ ë””ë²„ê¹…ìš© ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            "blood_type": final_state.get("blood_type"),
            "mood": final_state.get("mood_state"),
            "thought": final_state.get("internal_thought"),
            "search_results": final_state.get("search_results"),
            "summary": final_state.get("summary"),
            "active_tools": final_state.get("enabled_tools")
        }

        # ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        return {
            "status": "success", 
            "response": ai_response,
            "metadata": metadata
        }
        
    except Exception as e:
        logger.error(f"âŒ ì±„íŒ… ì‹¤í–‰ ì—ëŸ¬: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run("supporter_ai.main:app", host="0.0.0.0", port=settings.APP_PORT, reload=settings.DEBUG)