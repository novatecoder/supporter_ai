# src/supporter_ai/main.py
import traceback
import uvicorn
import time
from contextlib import asynccontextmanager
from typing import Dict, Any, List, Optional
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from loguru import logger

from supporter_ai.graph.workflow import create_supporter_workflow
from supporter_ai.common.config import settings
from supporter_ai.common.db_utils import init_db  # ì¶”ê°€ëœ ì„í¬íŠ¸

# ì•± ìƒíƒœ ê³µìœ 
app_state: Dict[str, Any] = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ DB ì´ˆê¸°í™” ë° ë­ê·¸ë˜í”„ ì—”ì§„ ë¡œë”©"""
    try:
        logger.info("ğŸš€ Supporter AI í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ ë¡œë”© ì¤‘...")
        
        # 1. DB ë° Qdrant ì»¬ë ‰ì…˜ ì´ˆê¸°í™” (ì—¬ê¸°ì„œ ì»¬ë ‰ì…˜ì´ ìƒì„±ë©ë‹ˆë‹¤)
        await init_db() 
        
        # 2. ë­ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ì»´íŒŒì¼
        app_state["graph"] = await create_supporter_workflow()
        yield 
    except Exception as e:
        logger.error(f"âŒ ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {traceback.format_exc()}")
        raise e
    finally:
        app_state.clear()

app = FastAPI(title="Supporter AI API", lifespan=lifespan)

# í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ ê·œê²©
class ChatRequest(BaseModel):
    user_id: str = "kwh_01"
    session_id: str = "sess_01"
    message: str = "ì•ˆë…•"
    blood_type: Optional[str] = "A"
    enabled_tools: Optional[List[str]] = []
    disabled_tools: Optional[List[str]] = []

async def run_post_processing(graph, state: Dict[str, Any]):
    try:
        summary = state.get("summary", "")
        if summary:
            logger.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ìš”ì•½ ì™„ë£Œ: {summary[:30]}...")
    except Exception as e:
        logger.error(f"âŒ ì‚¬í›„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

@app.post("/api/v1/chat")
async def chat(req: ChatRequest, background_tasks: BackgroundTasks):
    graph = app_state.get("graph")
    if not graph:
        raise HTTPException(status_code=503, detail="ì‹œìŠ¤í…œ ë¡œë”© ì¤‘")

    initial_state = {
        "input_text": req.message,
        "user_id": req.user_id,
        "session_id": req.session_id,
        "blood_type": req.blood_type,
        "enabled_tools": req.enabled_tools,
        "disabled_tools": req.disabled_tools,
        "messages": [],
        "ai_pad": {"p": 0.0, "a": 0.0, "d": 0.0} # ì´ˆê¸° PADê°’ ì„¤ì •
    }

    try:
        final_state = await graph.ainvoke(
            initial_state, 
            config={"recursion_limit": 50}
        )
        
        ai_response = final_state.get("final_output")
        if not ai_response or not isinstance(ai_response, dict):
            ai_response = {
                "text": "ë¯¸ì•ˆí•´, ëŒ€ë‹µì„ ì¤€ë¹„í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ìƒê²¼ì–´. ë‹¤ì‹œ ë§í•´ì¤„ë˜?",
                "emotion": "sad",
                "action": "none"
            }

        background_tasks.add_task(run_post_processing, graph, final_state)

        metadata = {
            "blood_type": final_state.get("blood_type"),
            "ai_pad": final_state.get("ai_pad"), # mood_state ëŒ€ì‹  ai_pad ë°˜í™˜
            "thought": final_state.get("internal_thought"),
            "search_results": final_state.get("search_results"),
            "summary": final_state.get("summary"),
            "active_tools": final_state.get("enabled_tools")
        }

        return {
            "status": "success", 
            "response": ai_response,
            "metadata": metadata
        }
        
    except Exception as e:
        logger.error(f"âŒ ì±„íŒ… ì‹¤í–‰ ì—ëŸ¬: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run("supporter_ai.main:app", host="0.0.0.0", port=settings.APP_PORT, reload=settings.DEBUG)